{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Working with workspace and client\n",
    "# details\n",
    "# pip install azureml-mlflow\n",
    "subscritpion_id=\"53eb2592-79d7-4d14-a92a-b97966ccf1c9\"\n",
    "resource_group=\"bdc\"\n",
    "workspace=\"ey2025\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authenticate\n",
    "from azure.identity import InteractiveBrowserCredential\n",
    "credential = InteractiveBrowserCredential(tenant_id=\"13a86542-2185-4187-8e07-7512f5525c55\")\n",
    "\n",
    "# create ML client\n",
    "from azure.ai.ml import MLClient\n",
    "ml_client = MLClient(credential=credential,subscription_id=subscritpion_id,\n",
    "                     resource_group_name=resource_group,workspace_name=workspace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace already exists\n"
     ]
    }
   ],
   "source": [
    "# access the workspace\n",
    "from azure.ai.ml.entities import Workspace\n",
    "try:\n",
    "    ws = ml_client.workspaces.get(workspace)\n",
    "    print(\"Workspace already exists\")\n",
    "except:\n",
    "    print(\"Creating new workspace\")\n",
    "    ws = Workspace(name=workspace,location='centralindia')\n",
    "    ws = ml_client.workspaces.begin_create(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'azureml://eastasia.api.azureml.ms/mlflow/v2.0/subscriptions/53eb2592-79d7-4d14-a92a-b97966ccf1c9/resourceGroups/bdc/providers/Microsoft.MachineLearningServices/workspaces/ey2025'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws.mlflow_tracking_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/labuser/anaconda3/lib/python3.12/site-packages/azureml/mlflow/_protos/aml_service_pb2.py:10: UserWarning: google.protobuf.service module is deprecated. RPC implementations should provide code generator plugins which generate code specific to the RPC implementation. service.py will be removed in Jan 2025\n",
      "  from google.protobuf import service as _service\n",
      "2025/03/05 05:12:13 INFO mlflow.tracking.fluent: Experiment with name 'Banking_Customer_churn' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='', creation_time=1741151533056, experiment_id='d56e240b-9e67-4c71-ab2e-0d8a77f8e744', last_update_time=None, lifecycle_stage='active', name='Banking_Customer_churn', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np, matplotlib.pyplot as plt, mlflow, mlflow.sklearn, os\n",
    "mlflow.set_tracking_uri(ws.mlflow_tracking_uri)\n",
    "mlflow.set_experiment(\"Banking_Customer_churn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\n",
    "url = \"https://raw.githubusercontent.com/anshupandey/Machine_Learning_Training/refs/heads/master/datasets/Bank_churn_modelling.csv\"\n",
    "df = pd.read_csv(url)\n",
    "x = df[['CreditScore', 'Geography', 'Gender', 'Age', 'Balance', 'NumOfProducts', 'IsActiveMember']]\n",
    "y =df['Exited']\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.2,stratify=y,random_state=5)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "transformer = ColumnTransformer([('ohe',OneHotEncoder(drop=\"first\"),[1,2]),],remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = xtest.copy()\n",
    "eval_data['label'] = ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/05 06:14:37 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/labuser/anaconda3/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2025/03/05 06:14:39 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/labuser/anaconda3/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run helpful_spider_1r299pwf at: https://eastasia.api.azureml.ms/mlflow/v2.0/subscriptions/53eb2592-79d7-4d14-a92a-b97966ccf1c9/resourceGroups/bdc/providers/Microsoft.MachineLearningServices/workspaces/ey2025/#/experiments/d56e240b-9e67-4c71-ab2e-0d8a77f8e744/runs/0923ee90-28c3-48e9-be71-9d717b523adf\n",
      "üß™ View experiment at: https://eastasia.api.azureml.ms/mlflow/v2.0/subscriptions/53eb2592-79d7-4d14-a92a-b97966ccf1c9/resourceGroups/bdc/providers/Microsoft.MachineLearningServices/workspaces/ey2025/#/experiments/d56e240b-9e67-4c71-ab2e-0d8a77f8e744\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model_pipeline = Pipeline([(\"transformer\",transformer),\n",
    "                               (\"model\",DecisionTreeClassifier(criterion='gini',min_samples_leaf=40,\n",
    "                                                               max_depth=8, class_weight='balanced',random_state=5))])\n",
    "    model_pipeline.fit(xtrain,ytrain)\n",
    "\n",
    "    model_uri = mlflow.get_artifact_uri(\"model\")\n",
    "\n",
    "    #model evaluation\n",
    "    #result = mlflow.evaluate(model=model_uri,data=eval_data,targets='label',model_type='classifier',evaluators=['default'],\n",
    "                             #evaluator_config={\"default\":{\"metric_prefix\":\"test_\",}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'churn_Pred' already exists. Creating a new version of this model...\n",
      "2025/03/05 06:18:29 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: churn_Pred, version 1\n",
      "Created version '1' of model 'churn_Pred'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1741155509662, current_stage='None', description=None, last_updated_timestamp=1741155509662, name='churn_Pred', run_id='0923ee90-28c3-48e9-be71-9d717b523adf', run_link='', source='azureml://eastasia.api.azureml.ms/mlflow/v2.0/subscriptions/53eb2592-79d7-4d14-a92a-b97966ccf1c9/resourceGroups/bdc/providers/Microsoft.MachineLearningServices/workspaces/ey2025/experiments/d56e240b-9e67-4c71-ab2e-0d8a77f8e744/runs/0923ee90-28c3-48e9-be71-9d717b523adf/artifacts/model', status='READY', status_message=None, tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# access the last run\n",
    "last_run = mlflow.last_active_run()\n",
    "runid = last_run.info.run_id\n",
    "\n",
    "#model registration\n",
    "model_uri = f\"runs:/{runid}/model\"\n",
    "model_name = \"churn_Pred\"\n",
    "mlflow.register_model(model_uri,model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEployment over ACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting AzureML/aciconfig.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile AzureML/aciconfig.json\n",
    "\n",
    "{\n",
    "    \"computeType\":\"aci\",\n",
    "    \"containerResourceRequirement\":\n",
    "    {\n",
    "        \"cpu\":2,\n",
    "        \"memoryInGB\":4\n",
    "    },\n",
    "    \"location\":\"eastasia\",\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from mlflow.deployments import get_deploy_client\n",
    "client = get_deploy_client(ws.mlflow_tracking_uri)\n",
    "\n",
    "# deployment configuraiton\n",
    "deploy_config_path = 'AzureML/aciconfig.json'\n",
    "config = {\"deploy-config-file\":deploy_config_path}\n",
    "model_version = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/labuser/anaconda3/lib/python3.12/site-packages/azureml/mlflow/deploy/_util.py:64: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_model_version_stages`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  if model_stage_or_version in client.get_model_version_stages(None, None):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01670a9d557c446da524d2994aaaec61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running\n",
      "2025-03-05 06:58:11+00:00 Creating Container Registry if not exists.\n",
      "2025-03-05 06:58:13+00:00 Use the existing image.\n",
      "2025-03-05 06:58:13+00:00 Generating deployment configuration.\n",
      "2025-03-05 06:58:17+00:00 Submitting deployment to compute.\n",
      "2025-03-05 06:58:31+00:00 Checking the status of deployment churn-aci....\n",
      "2025-03-05 06:59:44+00:00 Checking the status of inference endpoint churn-aci..\n",
      "Failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to retrieve continuation token: Polling method 'MMSPolling' doesn't support get_continuation_token\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Error while creating deployment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationFailed\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/azureml/mlflow/deploy/_mms/polling/mms_poller.py:79\u001b[0m, in \u001b[0;36mMMSPolling.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll()\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BadStatus \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/azureml/mlflow/deploy/_mms/polling/mms_poller.py:180\u001b[0m, in \u001b[0;36mMMSPolling._poll\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _failed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus()):\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_failure()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _succeeded(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus()):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/azureml/mlflow/deploy/_mms/polling/mms_poller.py:226\u001b[0m, in \u001b[0;36mMMSPolling._handle_failure\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m     logs_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCurrent sub-operation type not known, more logs unavailable.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 226\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OperationFailed(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mService deployment polling reached non-successful terminal state, current \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    227\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mservice state: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    228\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOperation ID: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    230\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    231\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_status, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operation\u001b[38;5;241m.\u001b[39mget_polling_url()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    232\u001b[0m                                   logs_response, format_error_response))\n",
      "\u001b[0;31mOperationFailed\u001b[0m: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: c990dfe0-2cb0-4feb-a35d-2fc49a18028f\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Aci Deployment failed with exception: Error in entry script, ImportError: cannot import name 'formatargspec' from 'inspect' (/azureml-envs/azureml_7a640ae2111e1c3a901fea35ffdb338d/lib/python3.12/inspect.py). Did you mean: 'formatargvalues'?, please run print(service.get_logs()) to get details.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Error in entry script, ImportError: cannot import name 'formatargspec' from 'inspect' (/azureml-envs/azureml_7a640ae2111e1c3a901fea35ffdb338d/lib/python3.12/inspect.py). Did you mean: 'formatargvalues'?, please run print(service.get_logs()) to get details.\"\n    }\n  ]\n}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/azureml/mlflow/deploy/deployment_client.py:501\u001b[0m, in \u001b[0;36mAzureMLDeploymentClient._v1_create_deployment\u001b[0;34m(self, name, model_name, model_version, create_deployment_config, v1_deploy_config, no_wait)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 501\u001b[0m     deployment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mms_client\u001b[38;5;241m.\u001b[39mcreate_service(\n\u001b[1;32m    502\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, model_name\u001b[38;5;241m=\u001b[39mmodel_name, model_version\u001b[38;5;241m=\u001b[39mmodel_version, deploy_config\u001b[38;5;241m=\u001b[39mv1_deploy_config,\n\u001b[1;32m    503\u001b[0m         no_wait\u001b[38;5;241m=\u001b[39mno_wait\n\u001b[1;32m    504\u001b[0m     )\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m no_wait:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/azureml/mlflow/deploy/_mms/mms_client.py:57\u001b[0m, in \u001b[0;36mMmsDeploymentClient.create_service\u001b[0;34m(self, name, model_name, model_version, deploy_config, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_wait \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     poller\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_service(name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/azure/core/polling/_poller.py:254\u001b[0m, in \u001b[0;36mLROPoller.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the result of the long running operation, or\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03mthe result available after the specified timeout.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03m:raises ~azure.core.exceptions.HttpResponseError: Server problem with the query.\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_polling_method\u001b[38;5;241m.\u001b[39mresource()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/azure/core/tracing/decorator.py:116\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m     span\u001b[38;5;241m.\u001b[39madd_attribute(key, value)\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/azure/core/polling/_poller.py:273\u001b[0m, in \u001b[0;36mLROPoller.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# Let's handle possible None in forgiveness here\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;66;03m# https://github.com/python/mypy/issues/8165\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# Was None\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/azure/core/polling/_poller.py:188\u001b[0m, in \u001b[0;36mLROPoller._start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_polling_method\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m AzureError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/azureml/mlflow/deploy/_mms/polling/mms_poller.py:97\u001b[0m, in \u001b[0;36mMMSPolling.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OperationFailed \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(\n\u001b[1;32m     98\u001b[0m         response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipeline_response\u001b[38;5;241m.\u001b[39mhttp_response,\n\u001b[1;32m     99\u001b[0m         error\u001b[38;5;241m=\u001b[39merr\n\u001b[1;32m    100\u001b[0m     )\n",
      "\u001b[0;31mHttpResponseError\u001b[0m: (AciDeploymentFailed) Aci Deployment failed with exception: Error in entry script, ImportError: cannot import name 'formatargspec' from 'inspect' (/azureml-envs/azureml_7a640ae2111e1c3a901fea35ffdb338d/lib/python3.12/inspect.py). Did you mean: 'formatargvalues'?, please run print(service.get_logs()) to get details.\nCode: AciDeploymentFailed\nMessage: Aci Deployment failed with exception: Error in entry script, ImportError: cannot import name 'formatargspec' from 'inspect' (/azureml-envs/azureml_7a640ae2111e1c3a901fea35ffdb338d/lib/python3.12/inspect.py). Did you mean: 'formatargvalues'?, please run print(service.get_logs()) to get details.\nException Details:\t(CrashLoopBackOff) Error in entry script, ImportError: cannot import name 'formatargspec' from 'inspect' (/azureml-envs/azureml_7a640ae2111e1c3a901fea35ffdb338d/lib/python3.12/inspect.py). Did you mean: 'formatargvalues'?, please run print(service.get_logs()) to get details.\n\tCode: CrashLoopBackOff\n\tMessage: Error in entry script, ImportError: cannot import name 'formatargspec' from 'inspect' (/azureml-envs/azureml_7a640ae2111e1c3a901fea35ffdb338d/lib/python3.12/inspect.py). Did you mean: 'formatargvalues'?, please run print(service.get_logs()) to get details.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m webservice \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mcreate_deployment(model_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels:/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      2\u001b[0m                                       config\u001b[38;5;241m=\u001b[39mconfig,name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchurn-aci\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/azureml/mlflow/deploy/deployment_client.py:134\u001b[0m, in \u001b[0;36mAzureMLDeploymentClient.create_deployment\u001b[0;34m(self, name, model_uri, flavor, config, endpoint)\u001b[0m\n\u001b[1;32m    131\u001b[0m         v1_deploy_config \u001b[38;5;241m=\u001b[39m AciServiceDeploymentConfiguration()\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m v1_deploy_config:\n\u001b[0;32m--> 134\u001b[0m     deployment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v1_create_deployment(name, model_name, model_version, config,\n\u001b[1;32m    135\u001b[0m                                             v1_deploy_config, no_wait)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     deployment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v2_create_deployment_new(name, model_name, model_version, v2_deploy_config, endpoint)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/azureml/mlflow/deploy/deployment_client.py:511\u001b[0m, in \u001b[0;36mAzureMLDeploymentClient._v1_create_deployment\u001b[0;34m(self, name, model_name, model_version, create_deployment_config, v1_deploy_config, no_wait)\u001b[0m\n\u001b[1;32m    507\u001b[0m         _logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAzureML deployment in progress, you can use get_deployment to check on the \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    508\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent deployment status.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError while creating deployment\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m deployment\u001b[38;5;241m.\u001b[39mserialize()\n",
      "\u001b[0;31mMlflowException\u001b[0m: Error while creating deployment"
     ]
    }
   ],
   "source": [
    "webservice = client.create_deployment(model_uri=f\"models:/{model_name}/{model_version}\",\n",
    "                                      config=config,name='churn-aci')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
